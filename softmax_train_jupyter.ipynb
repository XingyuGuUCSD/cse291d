{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "train_data_dir = '../keras/dataset/lfw_mtcnnpy_gray_picked_10_8_train_valid/train'\n",
    "validation_data_dir = '../keras/dataset/lfw_mtcnnpy_gray_picked_10_8_train_valid/valid'\n",
    "cnt = 0\n",
    "cnt_ = 0\n",
    "for subfolder in os.listdir(train_data_dir):\n",
    "    cnt_ += 1\n",
    "    subfolder_path = train_data_dir + \"/\" + subfolder\n",
    "    for file_ in os.listdir(subfolder_path):\n",
    "        cnt += 1\n",
    "print \"num of trainset is: \", cnt\n",
    "print \"num of trainset folder is: \", cnt_\n",
    "\n",
    "cnt = 0\n",
    "cnt_ = 0\n",
    "for subfolder in os.listdir(validation_data_dir):\n",
    "    cnt_ += 1\n",
    "    subfolder_path = validation_data_dir + \"/\" + subfolder\n",
    "    for file_ in os.listdir(subfolder_path):\n",
    "        cnt += 1\n",
    "print \"num of valid is: \", cnt\n",
    "print \"num of trainset folder is: \", cnt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model \n",
    "from keras.layers import Flatten, Dropout, Dense, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from utility import preprocess_image\n",
    "from keras.models import load_model \n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, 'model')\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Training Config Parameters\n",
    "run_dir = './train_run_picked_423_aug'\n",
    "if not os.path.exists(run_dir):\n",
    "    os.makedirs(run_dir)\n",
    "\n",
    "nb_train_samples = 37002\n",
    "nb_validation_samples = 4126\n",
    "save_step = 10\n",
    "epochs = 30000\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "momentum = 0.99\n",
    "fine_tuning_ture = 1\n",
    "fine_tuning_model_path = \"./\" + run_dir + \"/\" + \"weights-improvement-340-0.69-0.84-0.89.hdf5\"\n",
    "initial_epoch= 340\n",
    "\n",
    "# GPU Usage Control\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare network\n",
    "# base model selection\n",
    "bm = 6\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 80,80\n",
    "num_classes = 423\n",
    "#0 -- VGG16 (224x224)\n",
    "#1 -- Mobilenet (224x224)\n",
    "#2 -- LeNet-5 (32x32)\n",
    "#3 -- GesNet (32x32)\n",
    "#4 -- ObjNet (80x80)\n",
    "#5 -- ResNet-18 (224x224)\n",
    "#6 -- FaceNet (80x80)\n",
    "#7 -- VerifyNet (96x96)\n",
    "#8 -- ResNet-50 (224x224)\n",
    "#9 -- Yolo-v2-tiny (224x224)\n",
    "#10-- Yolo-v2-tiny-lite (224x224)\n",
    "#11-- Yolo-v2 (224x224)\n",
    "#Strarting from random initialization\n",
    "#if fine tuning from pre-trained model : weight = 'imagenet'\n",
    "if(fine_tuning_ture == 0):\n",
    "    #define input image size\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, img_width, img_height)\n",
    "    else:\n",
    "        input_shape = (img_width, img_height, 1)\n",
    "    \n",
    "    #load predefined base network model\n",
    "    if (bm==0):\n",
    "        from keras.applications.vgg16 import VGG16 #VGG\n",
    "        base_model = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    elif (bm==1):\n",
    "        from keras.applications.mobilenet import MobileNet #Mobilenet\n",
    "        base_model = MobileNet(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    elif (bm==2):    \n",
    "        from lenet import LeNet #LeNet-5\n",
    "        base_model = LeNet(include_top=False, weights=None, input_shape=input_shape)\n",
    "    elif (bm==3):\n",
    "        from gesnet import GesNet #GesNet\n",
    "        base_model = GesNet(include_top=False, weights=None, input_shape=input_shape)\n",
    "    elif (bm==4):\n",
    "        from objnet import ObjNet #ObjNet\n",
    "        base_model = ObjNet(include_top=False, weights=None, input_shape=input_shape)\n",
    "    elif (bm==5):\n",
    "        from resnet_18 import ResNet #ResNet-18\n",
    "        base_model = ResNet(include_top=False, weights=None, input_shape=input_shape)\n",
    "    elif (bm==6):\n",
    "        from facenet import FaceNet #FaceNet\n",
    "        base_model = FaceNet(include_top=False, weights=None, input_shape=input_shape)\n",
    "    elif (bm==7):\n",
    "        from verifynet_96_7x7 import VerifyNet #VerifyNet\n",
    "        base_model = VerifyNet(include_top=False, weights=None, input_shape=input_shape)\n",
    "    elif (bm==8):\n",
    "        from keras.applications.resnet50 import ResNet50 # ResNet-50\n",
    "        base_model = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    elif (bm==9):\n",
    "        from yolo import Yolo_v2_tiny #Yolo_v2_tiny\n",
    "        base_model = Yolo_v2_tiny(include_top=False, weights=None, input_shape=input_shape)\n",
    "    elif (bm==10):\n",
    "        from yolo import Yolo_v2_tiny_lite #Yolo_v2_tiny_lite\n",
    "        base_model = Yolo_v2_tiny_lite(include_top=False, weights=None, input_shape=input_shape)\n",
    "    elif (bm==11):\n",
    "        from yolo import Yolo_v2 #Yolo_v2\n",
    "        base_model = Yolo_v2(include_top=False, weights=None, input_shape=input_shape)        \n",
    "        \n",
    "    #redefine last layer\n",
    "    x = base_model.output\n",
    "    #GesNet #ObjNet\n",
    "    if(bm == 3 or bm == 4 or bm == 6 or bm == 7):\n",
    "        x = Flatten()(x)\n",
    "    #ResNet-18\n",
    "    elif(bm == 5):\n",
    "        x = AveragePooling2D(pool_size=(7, 7))(x)\n",
    "        x = Flatten()(x)\n",
    "    else:\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "    #convert to number of classes\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "else:\n",
    "    model = load_model(fine_tuning_model_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare ImageDataGenerator\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.9,\n",
    "    height_shift_range=0.9,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    preprocessing_function=preprocess_image)\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_image)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    shuffle = True,\n",
    "    )\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start to train\n",
    "#compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=learning_rate, momentum=momentum), metrics=['accuracy']    )\n",
    "\n",
    "#setup check point\n",
    "filepath=os.path.join(run_dir, \"weights-improvement-{epoch:02d}-{val_loss:.2f}-{acc:.2f}-{val_acc:.2f}.hdf5\")\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "checkpoint = ModelCheckpoint(filepath,period=save_step)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "#start to train\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    callbacks=callbacks_list,\n",
    "    initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
