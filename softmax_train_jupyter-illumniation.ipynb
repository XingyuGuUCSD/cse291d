{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of trainset is:  17194\n",
      "num of trainset folder is:  452\n",
      "num of valid is:  2103\n",
      "num of trainset folder is:  452\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "train_data_dir = '../keras/dataset/lfw_mtcnnpy_160_gray_train_valid/train'\n",
    "validation_data_dir = '../keras/dataset/lfw_mtcnnpy_160_gray_train_valid/valid'\n",
    "cnt = 0\n",
    "cnt_ = 0\n",
    "for subfolder in os.listdir(train_data_dir):\n",
    "    cnt_ += 1\n",
    "    subfolder_path = train_data_dir + \"/\" + subfolder\n",
    "    for file_ in os.listdir(subfolder_path):\n",
    "        cnt += 1\n",
    "print \"num of trainset is: \", cnt\n",
    "print \"num of trainset folder is: \", cnt_\n",
    "\n",
    "cnt = 0\n",
    "cnt_ = 0\n",
    "for subfolder in os.listdir(validation_data_dir):\n",
    "    cnt_ += 1\n",
    "    subfolder_path = validation_data_dir + \"/\" + subfolder\n",
    "    for file_ in os.listdir(subfolder_path):\n",
    "        cnt += 1\n",
    "print \"num of valid is: \", cnt\n",
    "print \"num of trainset folder is: \", cnt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model \n",
    "from keras.layers import Flatten, Dropout, Dense, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from utility import preprocess_image\n",
    "from keras.models import load_model \n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, 'model')\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Training Config Parameters\n",
    "run_dir = 'train_run'\n",
    "nb_train_samples = 17194\n",
    "nb_validation_samples = 2103\n",
    "save_step = 10\n",
    "epochs = 30000\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "fine_tuning_ture = 1\n",
    "fine_tuning_model_path = \"./\" + run_dir + \"/\" + \"weights-improvement-90-2.44-0.10-0.23.hdf5\"\n",
    "initial_epoch=91\n",
    "\n",
    "# GPU Usage Control\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare network\n",
    "# base model selection\n",
    "bm = 6\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 80,80\n",
    "num_classes = 452\n",
    "#0 -- VGG16 (224x224)\n",
    "#1 -- Mobilenet (224x224)\n",
    "#2 -- LeNet-5 (32x32)\n",
    "#3 -- GesNet (32x32)\n",
    "#4 -- ObjNet (80x80)\n",
    "#5 -- ResNet-18 (224x224)\n",
    "#6 -- FaceNet (80x80)\n",
    "#7 -- VerifyNet (96x96)\n",
    "#8 -- ResNet-50 (224x224)\n",
    "#9 -- Yolo-v2-tiny (224x224)\n",
    "#10-- Yolo-v2-tiny-lite (224x224)\n",
    "#11-- Yolo-v2 (224x224)\n",
    "#Strarting from random initialization\n",
    "#if fine tuning from pre-trained model : weight = 'imagenet'\n",
    "if(fine_tuning_ture == 0):\n",
    "    #define input image size\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, img_width, img_height)\n",
    "    else:\n",
    "        input_shape = (img_width, img_height, 1)\n",
    "    \n",
    "    #load predefined base network model\n",
    "    if (bm==0):\n",
    "        from keras.applications.vgg16 import VGG16 #VGG\n",
    "        base_model = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    elif (bm==1):\n",
    "        from keras.applications.mobilenet import MobileNet #Mobilenet\n",
    "        base_model = MobileNet(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    elif (bm==2):    \n",
    "        from lenet import LeNet #LeNet-5\n",
    "        base_model = LeNet(include_top=False, weights=None, input_shape=input_shape)\n",
    "    elif (bm==3):\n",
    "        from gesnet import GesNet #GesNet\n",
    "        base_model = GesNet(include_top=False, weights=None, input_shape=input_shape)\n",
    "    elif (bm==4):\n",
    "        from objnet import ObjNet #ObjNet\n",
    "        base_model = ObjNet(include_top=False, weights=None, input_shape=input_shape)\n",
    "    elif (bm==5):\n",
    "        from resnet_18 import ResNet #ResNet-18\n",
    "        base_model = ResNet(include_top=False, weights=None, input_shape=input_shape)\n",
    "    elif (bm==6):\n",
    "        from facenet import FaceNet #FaceNet\n",
    "        base_model = FaceNet(include_top=False, weights=None, input_shape=input_shape)\n",
    "    elif (bm==7):\n",
    "        from verifynet_96_7x7 import VerifyNet #VerifyNet\n",
    "        base_model = VerifyNet(include_top=False, weights=None, input_shape=input_shape)\n",
    "    elif (bm==8):\n",
    "        from keras.applications.resnet50 import ResNet50 # ResNet-50\n",
    "        base_model = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    elif (bm==9):\n",
    "        from yolo import Yolo_v2_tiny #Yolo_v2_tiny\n",
    "        base_model = Yolo_v2_tiny(include_top=False, weights=None, input_shape=input_shape)\n",
    "    elif (bm==10):\n",
    "        from yolo import Yolo_v2_tiny_lite #Yolo_v2_tiny_lite\n",
    "        base_model = Yolo_v2_tiny_lite(include_top=False, weights=None, input_shape=input_shape)\n",
    "    elif (bm==11):\n",
    "        from yolo import Yolo_v2 #Yolo_v2\n",
    "        base_model = Yolo_v2(include_top=False, weights=None, input_shape=input_shape)        \n",
    "        \n",
    "    #redefine last layer\n",
    "    x = base_model.output\n",
    "    #GesNet #ObjNet\n",
    "    if(bm == 3 or bm == 4 or bm == 6 or bm == 7):\n",
    "        x = Flatten()(x)\n",
    "    #ResNet-18\n",
    "    elif(bm == 5):\n",
    "        x = AveragePooling2D(pool_size=(7, 7))(x)\n",
    "        x = Flatten()(x)\n",
    "    else:\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "    #convert to number of classes\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "else:\n",
    "    model = load_model(fine_tuning_model_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 80, 80, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 40, 40, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 40, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 20, 20, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 5, 5, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 452)               58308     \n",
      "=================================================================\n",
      "Total params: 335,492\n",
      "Trainable params: 335,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17188 images belonging to 452 classes.\n",
      "Found 2103 images belonging to 452 classes.\n"
     ]
    }
   ],
   "source": [
    "# prepare ImageDataGenerator\n",
    "train_data_dir = '../keras/dataset/lfw_mtcnnpy_160_gray_train_valid/train'\n",
    "validation_data_dir = '../keras/dataset/lfw_mtcnnpy_160_gray_train_valid/valid'\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.9,\n",
    "    height_shift_range=0.9,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    preprocessing_function=preprocess_image)\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_image)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    shuffle = True,\n",
    "    )\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/30000\n",
      "268/268 [==============================] - 27s 102ms/step - loss: 3.1201 - acc: 0.1340 - val_loss: 2.0678 - val_acc: 0.3018\n",
      "Epoch 93/30000\n",
      "268/268 [==============================] - 38s 144ms/step - loss: 3.0258 - acc: 0.1381 - val_loss: 2.0334 - val_acc: 0.3145\n",
      "Epoch 94/30000\n",
      "268/268 [==============================] - 40s 151ms/step - loss: 2.9566 - acc: 0.1435 - val_loss: 1.9603 - val_acc: 0.3447\n",
      "Epoch 95/30000\n",
      "268/268 [==============================] - 38s 142ms/step - loss: 2.9094 - acc: 0.1493 - val_loss: 1.9521 - val_acc: 0.3394\n",
      "Epoch 96/30000\n",
      "268/268 [==============================] - 38s 142ms/step - loss: 2.8910 - acc: 0.1559 - val_loss: 1.8896 - val_acc: 0.3525\n",
      "Epoch 97/30000\n",
      "268/268 [==============================] - 40s 148ms/step - loss: 2.8672 - acc: 0.1559 - val_loss: 1.8644 - val_acc: 0.3599\n",
      "Epoch 98/30000\n",
      "268/268 [==============================] - 40s 148ms/step - loss: 2.8685 - acc: 0.1554 - val_loss: 1.8571 - val_acc: 0.3618\n",
      "Epoch 99/30000\n",
      "268/268 [==============================] - 37s 139ms/step - loss: 2.8527 - acc: 0.1543 - val_loss: 1.8528 - val_acc: 0.3579\n",
      "Epoch 100/30000\n",
      "268/268 [==============================] - 38s 142ms/step - loss: 2.8301 - acc: 0.1567 - val_loss: 1.8317 - val_acc: 0.3560\n",
      "Epoch 101/30000\n",
      "268/268 [==============================] - 34s 127ms/step - loss: 2.8271 - acc: 0.1575 - val_loss: 1.8874 - val_acc: 0.3638\n",
      "Epoch 102/30000\n",
      "268/268 [==============================] - 38s 142ms/step - loss: 2.7978 - acc: 0.1615 - val_loss: 1.8005 - val_acc: 0.3662\n",
      "Epoch 103/30000\n",
      "268/268 [==============================] - 36s 135ms/step - loss: 2.8090 - acc: 0.1622 - val_loss: 1.7956 - val_acc: 0.3804\n",
      "Epoch 104/30000\n",
      "268/268 [==============================] - 37s 139ms/step - loss: 2.7871 - acc: 0.1628 - val_loss: 1.8009 - val_acc: 0.3774\n",
      "Epoch 105/30000\n",
      "268/268 [==============================] - 37s 138ms/step - loss: 2.8028 - acc: 0.1590 - val_loss: 1.7303 - val_acc: 0.3892\n",
      "Epoch 106/30000\n",
      "268/268 [==============================] - 37s 139ms/step - loss: 2.7770 - acc: 0.1637 - val_loss: 1.7397 - val_acc: 0.3804\n",
      "Epoch 107/30000\n",
      "268/268 [==============================] - 36s 133ms/step - loss: 2.7601 - acc: 0.1667 - val_loss: 1.7653 - val_acc: 0.3730\n",
      "Epoch 108/30000\n",
      "268/268 [==============================] - 36s 134ms/step - loss: 2.7641 - acc: 0.1654 - val_loss: 1.7457 - val_acc: 0.3760\n",
      "Epoch 109/30000\n",
      "268/268 [==============================] - 37s 137ms/step - loss: 2.7620 - acc: 0.1662 - val_loss: 1.7371 - val_acc: 0.3872\n",
      "Epoch 110/30000\n",
      "268/268 [==============================] - 38s 144ms/step - loss: 2.7609 - acc: 0.1677 - val_loss: 1.7399 - val_acc: 0.3916\n",
      "Epoch 111/30000\n",
      "268/268 [==============================] - 37s 137ms/step - loss: 2.7397 - acc: 0.1643 - val_loss: 1.7272 - val_acc: 0.3916\n",
      "Epoch 112/30000\n",
      "268/268 [==============================] - 35s 131ms/step - loss: 2.7158 - acc: 0.1771 - val_loss: 1.7119 - val_acc: 0.4038\n",
      "Epoch 113/30000\n",
      "268/268 [==============================] - 35s 130ms/step - loss: 2.7314 - acc: 0.1720 - val_loss: 1.6829 - val_acc: 0.3931\n",
      "Epoch 114/30000\n",
      "268/268 [==============================] - 37s 139ms/step - loss: 2.7172 - acc: 0.1695 - val_loss: 1.6689 - val_acc: 0.3979\n",
      "Epoch 115/30000\n",
      "268/268 [==============================] - 37s 139ms/step - loss: 2.7069 - acc: 0.1729 - val_loss: 1.6803 - val_acc: 0.3999\n",
      "Epoch 116/30000\n",
      "268/268 [==============================] - 37s 137ms/step - loss: 2.7193 - acc: 0.1726 - val_loss: 1.6644 - val_acc: 0.4014\n",
      "Epoch 117/30000\n",
      "268/268 [==============================] - 33s 122ms/step - loss: 2.6882 - acc: 0.1764 - val_loss: 1.6555 - val_acc: 0.4058\n",
      "Epoch 118/30000\n",
      "268/268 [==============================] - 31s 117ms/step - loss: 2.7058 - acc: 0.1733 - val_loss: 1.6306 - val_acc: 0.4111\n",
      "Epoch 119/30000\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 2.7009 - acc: 0.1704 - val_loss: 1.6849 - val_acc: 0.4121\n",
      "Epoch 120/30000\n",
      "268/268 [==============================] - 32s 120ms/step - loss: 2.6838 - acc: 0.1776 - val_loss: 1.6199 - val_acc: 0.4121\n",
      "Epoch 121/30000\n",
      "268/268 [==============================] - 30s 113ms/step - loss: 2.6754 - acc: 0.1796 - val_loss: 1.6291 - val_acc: 0.4072\n",
      "Epoch 122/30000\n",
      "268/268 [==============================] - 31s 115ms/step - loss: 2.6799 - acc: 0.1796 - val_loss: 1.6326 - val_acc: 0.4048\n",
      "Epoch 123/30000\n",
      "268/268 [==============================] - 32s 119ms/step - loss: 2.6765 - acc: 0.1764 - val_loss: 1.6138 - val_acc: 0.4087\n",
      "Epoch 124/30000\n",
      "268/268 [==============================] - 33s 121ms/step - loss: 2.6778 - acc: 0.1748 - val_loss: 1.5884 - val_acc: 0.4180\n",
      "Epoch 125/30000\n",
      "268/268 [==============================] - 32s 118ms/step - loss: 2.6809 - acc: 0.1789 - val_loss: 1.5894 - val_acc: 0.4155\n",
      "Epoch 126/30000\n",
      "268/268 [==============================] - 30s 113ms/step - loss: 2.6499 - acc: 0.1857 - val_loss: 1.5866 - val_acc: 0.4238\n",
      "Epoch 127/30000\n",
      "268/268 [==============================] - 31s 114ms/step - loss: 2.6610 - acc: 0.1804 - val_loss: 1.6186 - val_acc: 0.4077\n",
      "Epoch 128/30000\n",
      "268/268 [==============================] - 31s 114ms/step - loss: 2.6478 - acc: 0.1848 - val_loss: 1.6129 - val_acc: 0.4307\n",
      "Epoch 129/30000\n",
      "268/268 [==============================] - 30s 113ms/step - loss: 2.6528 - acc: 0.1783 - val_loss: 1.5472 - val_acc: 0.4243\n",
      "Epoch 130/30000\n",
      "268/268 [==============================] - 31s 116ms/step - loss: 2.6651 - acc: 0.1780 - val_loss: 1.6190 - val_acc: 0.4180\n",
      "Epoch 131/30000\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 2.6582 - acc: 0.1798 - val_loss: 1.5999 - val_acc: 0.4189\n",
      "Epoch 132/30000\n",
      "268/268 [==============================] - 31s 116ms/step - loss: 2.6567 - acc: 0.1797 - val_loss: 1.5554 - val_acc: 0.4351\n",
      "Epoch 133/30000\n",
      "268/268 [==============================] - 30s 112ms/step - loss: 2.6519 - acc: 0.1818 - val_loss: 1.5565 - val_acc: 0.4346\n",
      "Epoch 134/30000\n",
      "268/268 [==============================] - 31s 117ms/step - loss: 2.6412 - acc: 0.1822 - val_loss: 1.5481 - val_acc: 0.4316\n",
      "Epoch 135/30000\n",
      "268/268 [==============================] - 31s 117ms/step - loss: 2.6555 - acc: 0.1756 - val_loss: 1.5365 - val_acc: 0.4336\n",
      "Epoch 136/30000\n",
      "268/268 [==============================] - 31s 116ms/step - loss: 2.6297 - acc: 0.1810 - val_loss: 1.5225 - val_acc: 0.4380\n",
      "Epoch 137/30000\n",
      "268/268 [==============================] - 37s 138ms/step - loss: 2.6303 - acc: 0.1819 - val_loss: 1.5432 - val_acc: 0.4282\n",
      "Epoch 138/30000\n",
      "268/268 [==============================] - 37s 137ms/step - loss: 2.6162 - acc: 0.1887 - val_loss: 1.5080 - val_acc: 0.4443\n",
      "Epoch 139/30000\n",
      "268/268 [==============================] - 35s 130ms/step - loss: 2.6014 - acc: 0.1935 - val_loss: 1.5348 - val_acc: 0.4463\n",
      "Epoch 140/30000\n",
      "268/268 [==============================] - 31s 116ms/step - loss: 2.6287 - acc: 0.1844 - val_loss: 1.5281 - val_acc: 0.4502\n",
      "Epoch 141/30000\n",
      "268/268 [==============================] - 31s 116ms/step - loss: 2.6188 - acc: 0.1819 - val_loss: 1.5163 - val_acc: 0.4526\n",
      "Epoch 142/30000\n",
      "268/268 [==============================] - 34s 126ms/step - loss: 2.6136 - acc: 0.1833 - val_loss: 1.5097 - val_acc: 0.4473\n",
      "Epoch 143/30000\n",
      "268/268 [==============================] - 34s 128ms/step - loss: 2.6191 - acc: 0.1879 - val_loss: 1.5368 - val_acc: 0.4463\n",
      "Epoch 144/30000\n",
      "268/268 [==============================] - 33s 124ms/step - loss: 2.6009 - acc: 0.1871 - val_loss: 1.4869 - val_acc: 0.4468\n",
      "Epoch 145/30000\n",
      "268/268 [==============================] - 33s 123ms/step - loss: 2.5993 - acc: 0.1897 - val_loss: 1.5050 - val_acc: 0.4536\n",
      "Epoch 146/30000\n",
      "268/268 [==============================] - 34s 125ms/step - loss: 2.5980 - acc: 0.1863 - val_loss: 1.5037 - val_acc: 0.4482\n",
      "Epoch 147/30000\n",
      "268/268 [==============================] - 34s 127ms/step - loss: 2.6025 - acc: 0.1870 - val_loss: 1.5206 - val_acc: 0.4624\n",
      "Epoch 148/30000\n",
      "268/268 [==============================] - 34s 127ms/step - loss: 2.5942 - acc: 0.1884 - val_loss: 1.4781 - val_acc: 0.4629\n",
      "Epoch 149/30000\n",
      "268/268 [==============================] - 34s 126ms/step - loss: 2.5984 - acc: 0.1867 - val_loss: 1.4855 - val_acc: 0.4561\n",
      "Epoch 150/30000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 34s 127ms/step - loss: 2.5877 - acc: 0.1895 - val_loss: 1.4707 - val_acc: 0.4590\n",
      "Epoch 151/30000\n",
      "268/268 [==============================] - 33s 124ms/step - loss: 2.5902 - acc: 0.1905 - val_loss: 1.4246 - val_acc: 0.4727\n",
      "Epoch 152/30000\n",
      "268/268 [==============================] - 32s 121ms/step - loss: 2.5849 - acc: 0.1936 - val_loss: 1.4330 - val_acc: 0.4751\n",
      "Epoch 153/30000\n",
      "268/268 [==============================] - 35s 129ms/step - loss: 2.5739 - acc: 0.1923 - val_loss: 1.4891 - val_acc: 0.4561\n",
      "Epoch 154/30000\n",
      "217/268 [=======================>......] - ETA: 5s - loss: 2.5901 - acc: 0.1907"
     ]
    }
   ],
   "source": [
    "#start to train\n",
    "#compile model\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999), metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=learning_rate, momentum=momentum), metrics=['accuracy']    )\n",
    "\n",
    "#setup check point\n",
    "filepath=os.path.join(run_dir, \"weights-improvement-{epoch:02d}-{val_loss:.2f}-{acc:.2f}-{val_acc:.2f}.hdf5\")\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "checkpoint = ModelCheckpoint(filepath,period=save_step)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "#start to train\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    callbacks=callbacks_list,\n",
    "    initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
